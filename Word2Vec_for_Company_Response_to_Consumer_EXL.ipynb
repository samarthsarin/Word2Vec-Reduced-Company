{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec for Company Response to Consumer EXL",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTxLbquFIO8G",
        "colab_type": "code",
        "outputId": "9e0e8c2d-a54a-422e-baa8-0f411d178c0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaT127m3Isdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,GRU,Bidirectional,Convolution1D,Dense,GlobalMaxPool1D,Bidirectional,Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3ixb5RKJdbc",
        "colab_type": "code",
        "outputId": "3bc08245-6328-4245-93e6-f93ea0b01f66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/EXL Data/Company response reduced 50k.csv')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Consumer complaint narrative</th>\n",
              "      <th>Total Clean Text</th>\n",
              "      <th>After Stop Word Removal</th>\n",
              "      <th>Company response to consumer</th>\n",
              "      <th>Complaint ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>When I received the initial call, I asked the ...</td>\n",
              "      <td>when  receive the initial call  ask the agent ...</td>\n",
              "      <td>receive initial call ask agent stop call debt ...</td>\n",
              "      <td>Closed with non-monetary relief</td>\n",
              "      <td>2714037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Capital One applied my {$100.00} XXXX 2016 pay...</td>\n",
              "      <td>capital one apply my 100 00  2016 payment for ...</td>\n",
              "      <td>capital one apply 100 00 2016 payment card end...</td>\n",
              "      <td>Closed with monetary relief</td>\n",
              "      <td>1886231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>THIS COMPANY IS REPORTING AN ACCOUNT ON MY CRE...</td>\n",
              "      <td>this company be report an account on my credit...</td>\n",
              "      <td>company report account credit mine inaccurate ...</td>\n",
              "      <td>Closed with non-monetary relief</td>\n",
              "      <td>3448072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>So I recieved an email from my employer that m...</td>\n",
              "      <td>so  recieved an email from my employer that my...</td>\n",
              "      <td>recieved email employer wag garnish state woul...</td>\n",
              "      <td>Closed with non-monetary relief</td>\n",
              "      <td>3351230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XX/XX/XXXX, I started working with XXXX XXXX X...</td>\n",
              "      <td>start work with     and his assistant       ...</td>\n",
              "      <td>start work assistant regard streamline fh refi...</td>\n",
              "      <td>Others</td>\n",
              "      <td>3352054</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Consumer complaint narrative  ... Complaint ID\n",
              "0  When I received the initial call, I asked the ...  ...      2714037\n",
              "1  Capital One applied my {$100.00} XXXX 2016 pay...  ...      1886231\n",
              "2  THIS COMPANY IS REPORTING AN ACCOUNT ON MY CRE...  ...      3448072\n",
              "3  So I recieved an email from my employer that m...  ...      3351230\n",
              "4  XX/XX/XXXX, I started working with XXXX XXXX X...  ...      3352054\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_7G_cciJidk",
        "colab_type": "code",
        "outputId": "0d6fc7ba-d965-4fae-bfe7-b75c5202d699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "df['Company response to consumer'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Closed with non-monetary relief    56652\n",
              "Others                             50000\n",
              "Closed with monetary relief        26882\n",
              "Name: Company response to consumer, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLaZe_toJvvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def renaming(text):\n",
        "  if text == 'Closed with explanation':\n",
        "    return 'Others'\n",
        "  elif text == 'Closed':\n",
        "    return 'Others'\n",
        "  elif text == 'Untimely response':\n",
        "    return 'Others'\n",
        "  else:\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1zmkfZBKD0P",
        "colab_type": "code",
        "outputId": "d8bd858d-614f-44b4-9eb6-610164aa2bc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df['Company response to consumer'] = df['Company response to consumer'].progress_apply(renaming)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 133534/133534 [00:00<00:00, 901479.80it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVR22SSnRIHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df.sort_values(by = 'Company response to consumer',ascending=True,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7py8Y7XxRhWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvqXcWxtRmLn",
        "colab_type": "code",
        "outputId": "d8deb455-3a86-4347-922e-9400947eb97a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "df['Company response to consumer'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Closed with non-monetary relief    56652\n",
              "Others                             50000\n",
              "Closed with monetary relief        26882\n",
              "Name: Company response to consumer, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZc9ljTyR5hZ",
        "colab_type": "code",
        "outputId": "ff817419-bf75-46e2-efb2-c6e28ca6cf50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "#df = df[:130000]\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Consumer complaint narrative</th>\n",
              "      <th>Total Clean Text</th>\n",
              "      <th>After Stop Word Removal</th>\n",
              "      <th>Company response to consumer</th>\n",
              "      <th>Complaint ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My wife and I obtained a vehicle loan through ...</td>\n",
              "      <td>my wife and  obtain  vehicle loan through fift...</td>\n",
              "      <td>wife obtain vehicle loan fifth third bank 2016...</td>\n",
              "      <td>Closed with non-monetary relief</td>\n",
              "      <td>2704428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>To whom it may concern, XXXX negative accounts...</td>\n",
              "      <td>to whom it may concern  negative account    ch...</td>\n",
              "      <td>may concern negative account charge account mi...</td>\n",
              "      <td>Closed with non-monetary relief</td>\n",
              "      <td>1652669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Apparently, I made a simple error in my bill p...</td>\n",
              "      <td>apparently  make  simple error in my bill pay ...</td>\n",
              "      <td>apparently make simple error bill pay bank ame...</td>\n",
              "      <td>Closed with monetary relief</td>\n",
              "      <td>2470412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I activated and registered a prepaid XXXX card...</td>\n",
              "      <td>activate and register  prepay  card  use it f...</td>\n",
              "      <td>activate register prepay card use fully within...</td>\n",
              "      <td>Others</td>\n",
              "      <td>3331201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>On XXXX XXXX XXXX i went into XXXX on to use m...</td>\n",
              "      <td>on     go into  on to use my atm  withdraw  th...</td>\n",
              "      <td>go use atm withdraw come crook reach grab side...</td>\n",
              "      <td>Closed with monetary relief</td>\n",
              "      <td>1697770</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Consumer complaint narrative  ... Complaint ID\n",
              "0  My wife and I obtained a vehicle loan through ...  ...      2704428\n",
              "1  To whom it may concern, XXXX negative accounts...  ...      1652669\n",
              "2  Apparently, I made a simple error in my bill p...  ...      2470412\n",
              "3  I activated and registered a prepaid XXXX card...  ...      3331201\n",
              "4  On XXXX XXXX XXXX i went into XXXX on to use m...  ...      1697770\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDWLXPx2KIuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df['Total Clean Text']\n",
        "y = df['Company response to consumer']\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "y = le.fit_transform(y)\n",
        "y = to_categorical(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJKAobaGKiW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenizer.fit_on_texts(x)\n",
        "\n",
        "seq = tokenizer.texts_to_sequences(x)\n",
        "\n",
        "pad_seq = pad_sequences(seq,maxlen = 500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpq2N6A8Kq5F",
        "colab_type": "code",
        "outputId": "560a9d42-3710-4eea-d79c-6bc7ade287cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab_size = len(tokenizer.word_index)+1\n",
        "vocab_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26056"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMBNyvneK8r6",
        "colab_type": "code",
        "outputId": "a79e19f7-44b8-40b1-e087-2dcf87ac312f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_values = {}\n",
        "f = open('/content/drive/My Drive/Embeddings/glove.840B.300d.txt')\n",
        "for line in tqdm(f):\n",
        "  value = line.split(' ')\n",
        "  word = value[0]\n",
        "  coef = np.array(value[1:],dtype = 'float')\n",
        "  if coef is not None:\n",
        "    embedding_values[word] = coef"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2196018it [03:33, 10276.65it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYHkAGfKfUpl",
        "colab_type": "code",
        "outputId": "3b374548-9b7d-4f74-faf1-22a92a7292e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "word2vec = KeyedVectors.load_word2vec_format('/content/drive/My Drive/Embeddings/GoogleNews-vectors-negative300.bin', \\\n",
        "        binary=True)\n",
        "print('Found %s word vectors of word2vec' % len(word2vec.vocab))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 3000000 word vectors of word2vec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1vJkMMMLf_w",
        "colab_type": "code",
        "outputId": "b67a0264-4cf4-45db-b5ae-1d7f7389eaed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "all_embds = np.stack(embedding_values.values())\n",
        "mean,std = all_embds.mean(),all_embds.std()\n",
        "mean,std"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.005838497258278652, 0.4878208104560991)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qu0a-jaLtj3",
        "colab_type": "code",
        "outputId": "3a5a1a46-adfc-48c3-a1b1-3b1aa8d7aa4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_matrix = np.random.normal(mean,std,(vocab_size,300))\n",
        "for word,i in tqdm(tokenizer.word_index.items()):\n",
        "  value = embedding_values.get(word)\n",
        "  if value is not None:\n",
        "    embedding_matrix[i] = value"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 26055/26055 [00:00<00:00, 343755.40it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71HKwh4yfo2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in word2vec.vocab:\n",
        "        embedding_matrix[i] = word2vec.word_vec(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TpZB49cNsNP",
        "colab_type": "code",
        "outputId": "3d6dc3d5-32ba-4453-bb57-e02c8723c527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O4aE-jZMn8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size,300,input_length=500,weights = [embedding_matrix],trainable = False))\n",
        "model.add(Bidirectional(GRU(32,return_sequences=True)))\n",
        "model.add(Convolution1D(64,2,activation = 'relu'))\n",
        "model.add(Dense(64,activation = 'relu'))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(128,activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(3,activation = 'softmax'))\n",
        "\n",
        "model.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4SUpSjrIu3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(pad_seq,y,test_size = 0.15,random_state= 42,stratify = y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1UD3wFgNtIY",
        "colab_type": "code",
        "outputId": "6fe1dca3-9868-49dd-a75d-e6c5b493e76c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "model.fit(x_train,y_train,batch_size = 32,epochs = 5,validation_split = 0.15 )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "3015/3015 [==============================] - 517s 171ms/step - loss: 0.7844 - accuracy: 0.6094 - val_loss: 0.7303 - val_accuracy: 0.6461\n",
            "Epoch 2/5\n",
            "3015/3015 [==============================] - 515s 171ms/step - loss: 0.7137 - accuracy: 0.6589 - val_loss: 0.7115 - val_accuracy: 0.6650\n",
            "Epoch 3/5\n",
            "3015/3015 [==============================] - 515s 171ms/step - loss: 0.6849 - accuracy: 0.6762 - val_loss: 0.7020 - val_accuracy: 0.6695\n",
            "Epoch 4/5\n",
            "3015/3015 [==============================] - 515s 171ms/step - loss: 0.6615 - accuracy: 0.6910 - val_loss: 0.6873 - val_accuracy: 0.6749\n",
            "Epoch 5/5\n",
            "3015/3015 [==============================] - 515s 171ms/step - loss: 0.6399 - accuracy: 0.7027 - val_loss: 0.6914 - val_accuracy: 0.6766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f23047bb208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngH7jZlwXsur",
        "colab_type": "code",
        "outputId": "79a81b18-4b53-4621-af41-20acca7bcc01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "loss,acc = model.evaluate(x_test,y_test)\n",
        "loss,acc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "626/626 [==============================] - 43s 69ms/step - loss: 0.6845 - accuracy: 0.6788\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6844510436058044, 0.6788477897644043)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2zleDmCN-1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('Consumer response Word2Vec 500 Length Reduced.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNfKrledMX0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "# saving\n",
        "with open('tokenizer_Consumer_response_Word2Vec_500_Length Reduced.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6ABcGEEMn9I",
        "colab_type": "code",
        "outputId": "245854fe-3c93-4a93-db82-bc8dec32bc51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "le.classes_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Closed with monetary relief', 'Closed with non-monetary relief',\n",
              "       'Others'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Gxz3Peko2GP",
        "colab_type": "code",
        "outputId": "f8a782b0-bbd2-45c1-854f-aa6fa3118fd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "predictions = model.predict(x_test)\n",
        "for thresh in np.arange(0.5, 0.701, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    print(\"Precision score at threshold {0} is {1}\".format(thresh, metrics.precision_score(y_test, (predictions>thresh).astype(int),average=\"micro\")))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision score at threshold 0.5 is 0.704696499778467\n",
            "Precision score at threshold 0.51 is 0.7100267913127744\n",
            "Precision score at threshold 0.52 is 0.7163391023760634\n",
            "Precision score at threshold 0.53 is 0.7225981873111782\n",
            "Precision score at threshold 0.54 is 0.7302380803599325\n",
            "Precision score at threshold 0.55 is 0.7347631241997439\n",
            "Precision score at threshold 0.56 is 0.7404967389156071\n",
            "Precision score at threshold 0.57 is 0.7466693855356172\n",
            "Precision score at threshold 0.58 is 0.7534361851332398\n",
            "Precision score at threshold 0.59 is 0.7606701812667004\n",
            "Precision score at threshold 0.6 is 0.7673862702621946\n",
            "Precision score at threshold 0.61 is 0.772972556275054\n",
            "Precision score at threshold 0.62 is 0.7770076481835564\n",
            "Precision score at threshold 0.63 is 0.7830235236058563\n",
            "Precision score at threshold 0.64 is 0.7895407080397318\n",
            "Precision score at threshold 0.65 is 0.7940507436570429\n",
            "Precision score at threshold 0.66 is 0.7992029707454035\n",
            "Precision score at threshold 0.67 is 0.8026733968966162\n",
            "Precision score at threshold 0.68 is 0.8095607485697663\n",
            "Precision score at threshold 0.69 is 0.8147888030500652\n",
            "Precision score at threshold 0.7 is 0.8204353713154879\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YsSxVfwB2bk",
        "colab_type": "code",
        "outputId": "fd7d858e-cc99-4fc9-cebd-48b8eaec250d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "for thresh in np.arange(0.5, 0.701, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    print(\"Recall score at threshold {0} is {1}\".format(thresh, metrics.recall_score(y_test, (predictions>thresh).astype(int),average=\"micro\")))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall score at threshold 0.5 is 0.6352154161050372\n",
            "Recall score at threshold 0.51 is 0.6218361539613599\n",
            "Recall score at threshold 0.52 is 0.6095551894563427\n",
            "Recall score at threshold 0.53 is 0.59702461185163\n",
            "Recall score at threshold 0.54 is 0.5833957366082572\n",
            "Recall score at threshold 0.55 is 0.5729619090409864\n",
            "Recall score at threshold 0.56 is 0.5611302481154211\n",
            "Recall score at threshold 0.57 is 0.548399980030952\n",
            "Recall score at threshold 0.58 is 0.5363686286256303\n",
            "Recall score at threshold 0.59 is 0.5258349558184814\n",
            "Recall score at threshold 0.6 is 0.5128550746343168\n",
            "Recall score at threshold 0.61 is 0.5005741101292995\n",
            "Recall score at threshold 0.62 is 0.4868953122659877\n",
            "Recall score at threshold 0.63 is 0.4752633418201787\n",
            "Recall score at threshold 0.64 is 0.464280365433578\n",
            "Recall score at threshold 0.65 is 0.4530976985672208\n",
            "Recall score at threshold 0.66 is 0.440517198342569\n",
            "Recall score at threshold 0.67 is 0.42868553741700366\n",
            "Recall score at threshold 0.68 is 0.41680395387149916\n",
            "Recall score at threshold 0.69 is 0.4054215965253857\n",
            "Recall score at threshold 0.7 is 0.39324047726024663\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nW-cfhnB9LO",
        "colab_type": "code",
        "outputId": "931dc551-9b9c-44ec-e3d1-68f1d3e9d04b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "for thresh in np.arange(0.5, 0.701, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(y_test, (predictions>thresh).astype(int),average=\"micro\")))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score at threshold 0.5 is 0.6681544884081182\n",
            "F1 score at threshold 0.51 is 0.6630116569968596\n",
            "F1 score at threshold 0.52 is 0.6586471032473837\n",
            "F1 score at threshold 0.53 is 0.6538366911784806\n",
            "F1 score at threshold 0.54 is 0.6486096464450241\n",
            "F1 score at threshold 0.55 is 0.6438529073518275\n",
            "F1 score at threshold 0.56 is 0.6384549843794377\n",
            "F1 score at threshold 0.57 is 0.6323575972138272\n",
            "F1 score at threshold 0.58 is 0.6266367268379458\n",
            "F1 score at threshold 0.59 is 0.6218194698624475\n",
            "F1 score at threshold 0.6 is 0.6148183613621401\n",
            "F1 score at threshold 0.61 is 0.6076417295397388\n",
            "F1 score at threshold 0.62 is 0.5986557407236902\n",
            "F1 score at threshold 0.63 is 0.5915064152350182\n",
            "F1 score at threshold 0.64 is 0.5847217856020119\n",
            "F1 score at threshold 0.65 is 0.5769683099710754\n",
            "F1 score at threshold 0.66 is 0.5679711637487127\n",
            "F1 score at threshold 0.67 is 0.5588857431091151\n",
            "F1 score at threshold 0.68 is 0.5502900079093066\n",
            "F1 score at threshold 0.69 is 0.5414360957397161\n",
            "F1 score at threshold 0.7 is 0.5316549676025918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nKKnjFiB_UB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}